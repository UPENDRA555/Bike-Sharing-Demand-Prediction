{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "85aiEz2wzJ-7",
        "-Kee-DAl2viO",
        "gIfDvo9L0UH2"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    -\n",
        "#Bike Sharing Demand Prediction\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - Regression\n",
        "##### **Contribution**    - Individual\n",
        "##### **Team Member 1 -** Upendra Pratap Singh"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/UPENDRA555/Bike-Sharing-Demand-Prediction/tree/main"
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Currently Rental bikes are introduced in many urban cities for the enhancement of mobility comfort. It is important to make the rental bike available and accessible to the public at the right time as it lessens the waiting time. Eventually, providing the city with a stable supply of rental bikes becomes a major concern. The crucial part is the prediction of bike count required at each hour for the stable supply of rental bikes."
      ],
      "metadata": {
        "id": "mDgbUHAGgjLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.ticker as mtick\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# hide warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "DVE3Ddju8B5B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/SeoulBikeData.csv', encoding='unicode_escape')"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "df.head()"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.tail()"
      ],
      "metadata": {
        "id": "3r9O3Hkw9SWN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "print('The row & column count')\n",
        "df.shape"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "df.info()"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.dtypes"
      ],
      "metadata": {
        "id": "7ksoOerNAlTS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "duplicate_value=len(df[df.duplicated()])\n",
        "print('The number of duplicate value in theis data:', duplicate_value)\n",
        "df.groupby(df.columns.tolist(),as_index=False).size().head()"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df.drop_duplicates()"
      ],
      "metadata": {
        "id": "NRjrtK5OAxNz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "def show_missing():\n",
        "    missing = df.columns[df.isnull().any()].tolist()\n",
        "    return missing\n",
        "\n",
        "# Missing data counts and percentage\n",
        "print('Missing Data Count')\n",
        "print(df[show_missing()].isnull().sum().sort_values(ascending = False))\n",
        "print('--'*50)\n",
        "print('Missing Data Percentage')\n",
        "print(round(df[show_missing()].isnull().sum().sort_values(ascending = False)/len(df)*100,2))"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of missing value in each column\n",
        "df.isna().sum()"
      ],
      "metadata": {
        "id": "QmNQC_MJCXCD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "!pip install missingno"
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import missingno as msno\n",
        "msno.matrix(df)"
      ],
      "metadata": {
        "id": "2UAdJ8FH3m-f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "msno.bar(df)"
      ],
      "metadata": {
        "id": "wQZrGQsK4FNy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Description\n",
        "\n",
        "The dataset contains weather information (Temperature, Humidity, Windspeed, Visibility, Dewpoint, Solar radiation, Snowfall, Rainfall), the number of bikes rented per hour and date information.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Attribute Information:\n",
        "\n",
        "\n",
        "*   Date : year-month-day\n",
        "*   Rented Bike count - Count of bikes rented at each hour\n",
        "\n",
        "\n",
        "*   Hour - Hour of he day\n",
        "*   Temperature-Temperature in Celsius\n",
        "\n",
        "*   Humidity - %\n",
        "*   Windspeed - m/s\n",
        "\n",
        "*   Visibility - 10m\n",
        "*   Dew point temperature - Celsius\n",
        "\n",
        "*   Solar radiation - MJ/m2\n",
        "*   Rainfall - mm\n",
        "\n",
        "*   Snowfall - cm\n",
        "*   Seasons - Winter, Spring, Summer, Autumn\n",
        "\n",
        "*   Holiday - Holiday/No holiday\n",
        "*   Functional Day - NoFunc(Non Functional Hours), Fun(Functional hours)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "df.columns"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "df.describe()"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "df.nunique()"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code to make your dataset analysis ready.\n",
        "data = df.copy()\n",
        "data.head()"
      ],
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.dtypes"
      ],
      "metadata": {
        "id": "6fUbCf2Df9IB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Date columns to Date format conversion\n",
        "data['Date']= pd.to_datetime(data['Date'])"
      ],
      "metadata": {
        "id": "hNE3U-GbgMGC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "*   Changing the 'Date' column in three column 'Day', 'Month' And 'Year' columns  List item\n",
        "\n",
        "\n",
        "*   Create a another column is \"Weekend\" for Saterday and Sunday because we need this data\n",
        "\n"
      ],
      "metadata": {
        "id": "t6b--0O2OxoK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Changing the 'Date' column in three column 'Day', 'Month' And 'Year' columns List item\n",
        "data['Year'] = data['Date'].dt.year\n",
        "data['Month'] = data['Date'].dt.month\n",
        "data['Day'] = data['Date'].dt.day_name()"
      ],
      "metadata": {
        "id": "kt88rywWOxW0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a another column is \"Weekend\" for Saterday and Sunday\n",
        "data['Weekend']=data['Day'].apply(lambda x : 1 if x=='Saturday' or x=='Sunday' else 0 )"
      ],
      "metadata": {
        "id": "I0Deu9bp_8nF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   We are drop the Day and Year column and also a Date column\n",
        "*   Day column contais each day details of every month, we don't need this data for our relevence\n",
        "\n",
        "*   Year column contains only 2 unique number 2017 and 2018 for december to novenber only 1 year, so don't need a Year column for only 1 year\n",
        "\n",
        "\n",
        "*   We are drop a Date column because we are extracting a Day, Month and Year then there is no relevence in this dataset\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "mqrLsj_iSNt-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data=data.drop(columns=['Date','Day','Year'],axis=1)"
      ],
      "metadata": {
        "id": "RYNjg_z7SM8_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.columns"
      ],
      "metadata": {
        "id": "C2Ou3Z4QUSTB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.dtypes"
      ],
      "metadata": {
        "id": "uG8UI39wUVmG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are seen 'Hour', 'Month', and 'Weekend' column are shows a integer type but it is a categorical columns then convert these column into ctaegorical type"
      ],
      "metadata": {
        "id": "g1X6noAXVXH3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 'Hours', 'Month' and 'Weekend' are convert into category column\n",
        "data['Hour']= data['Hour'].astype('category')\n",
        "data['Month']= data['Month'].astype('category')\n",
        "data['Weekend']= data['Weekend'].astype('category')"
      ],
      "metadata": {
        "id": "tNNLgQ81WZ5J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data['Hour'].value_counts())\n",
        "print(data['Month'].value_counts())\n",
        "print(data['Weekend'].value_counts())"
      ],
      "metadata": {
        "id": "OPcp4n3FYNg2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "categorical_features= data.select_dtypes(include=['object', 'category'])\n",
        "categorical_features.head()"
      ],
      "metadata": {
        "id": "qg5paTdgd6QY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numerical_features= data.select_dtypes(include=['int64', 'float64'])\n",
        "numerical_features.head()"
      ],
      "metadata": {
        "id": "eOHUglC2we8d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## *** EDA(Exploratory data analysis)***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#### For Target variable"
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the Independent and dependent variable\n",
        "X=data.iloc[:,2:]\n",
        "y=data['Rented Bike Count']"
      ],
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.head()"
      ],
      "metadata": {
        "id": "lmQWXTwTznot"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y.head()"
      ],
      "metadata": {
        "id": "kSky88d70sNP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the distplot for Dependent variable\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.distplot(data['Rented Bike Count'], hist= True)\n",
        "plt.xlabel('Rented Bike Count')\n",
        "plt.ylabel('Density')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8iFgATR61RKF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the above distplot data are rightly skweness then applying square root to Rented Bike Count to improve skewness"
      ],
      "metadata": {
        "id": "Zo5o_o2_RfgA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply square root to improve skewnwess\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.distplot(np.sqrt(data['Rented Bike Count']), hist= True)\n",
        "plt.xlabel('Rented Bike Count')\n",
        "plt.ylabel('Density')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "EXHTcYnVzGFy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Categorical feature Analysis"
      ],
      "metadata": {
        "id": "fxH1LdPj4u0B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Find a total count of a unique value\n",
        "for colm in categorical_features:\n",
        "  data[colm].value_counts()\n",
        "  print(data[colm].value_counts())"
      ],
      "metadata": {
        "id": "7WSp4ubpLdpp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot a bar graph of a categorical feature\n",
        "for colm in categorical_features:\n",
        "  data[colm].value_counts().plot(kind= 'bar', figsize= (10, 10), fontsize=10, width= 0.3)\n",
        "  plt.xlabel(colm)\n",
        "  plt.ylabel('Count')\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "p8tKfXsmCeGt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot a barplot between a categorical feature and target feature\n",
        "for col in categorical_features:\n",
        "  plt.figure(figsize=(10,6))\n",
        "  sns.barplot(x=data[col], y= data['Rented Bike Count'])\n",
        "  plt.xlabel(col)\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "HxAzqXbS6YmA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ploting Box plot to visualize and trying to get information from plot\n",
        "for col in categorical_features:\n",
        "  sns.boxplot(x=data[col],y=data[\"Rented Bike Count\"])\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "0_HTd1Rw601I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot average rent over categorical feature\n",
        "for col in categorical_features:\n",
        "  avg_rent = data.groupby(col)['Rented Bike Count'].mean()\n",
        "  plt.figure(figsize=(20,4))\n",
        "  a=avg_rent.plot(legend=True,marker='o',title=\"Average Bikes Rented\")\n",
        "  a.set_xticks(range(len(avg_rent)));\n",
        "  a.set_xticklabels(avg_rent.index.tolist(), rotation=85);\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "2vfVOO-m8Vov"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   Rented Bike demand is high in morning 7 am to 9 am and evening 5 pm to 7 pm.\n",
        "*   Rented bike demand is high in summer season an low in winter season\n",
        "\n",
        "*   Rented bike demand is decresing in holidays.\n",
        "*   Peoples dont use reneted bikes in no functioning day.\n",
        "\n",
        "*   Rented bike demand is high in June month and low in January and Febuary month\n",
        "*   Rented bike demand is decrese in Weekend\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "AyUaC-bZJqRr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#anlysis of data by vizualisation\n",
        "fig,ax=plt.subplots(figsize=(20,8))\n",
        "sns.pointplot(data=data,x='Hour',y='Rented Bike Count',hue='Seasons',ax=ax)\n",
        "ax.set(title='Count of Rented bikes acording to seasons ')"
      ],
      "metadata": {
        "id": "E_9DFGhcHWjM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   In summer season the use of rented bike is high and peak time is 7am-9am and 7pm-5pm.\n",
        "*   In winter season the use of rented bike is very low because of snowfall.\n",
        "\n"
      ],
      "metadata": {
        "id": "aeN41Oe5HoOh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#anlysis of data by vizualisation\n",
        "fig,ax=plt.subplots(figsize=(20,8))\n",
        "sns.pointplot(data=data,x='Hour',y='Rented Bike Count',hue='Holiday',ax=ax)\n",
        "ax.set(title='Count of Rented bikes acording to Holiday ')"
      ],
      "metadata": {
        "id": "1mjAQuy8H4n7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   plot shows that in holiday people uses the rented bike from 2pm-8pm\n",
        "\n"
      ],
      "metadata": {
        "id": "2RQb1MTcIE4t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#anlysis of data by vizualisation\n",
        "fig,ax=plt.subplots(figsize=(20,8))\n",
        "sns.pointplot(data=data,x='Hour',y='Rented Bike Count',hue='Functioning Day',ax=ax)\n",
        "ax.set(title='Count of Rented bikes acording to Functioning Day ')"
      ],
      "metadata": {
        "id": "TEUO2oeNITIt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   Point plot which shows the use of rented bike in functioning daya or not, and it clearly shows that,\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "*   Peoples dont use reneted bikes in no functioning day.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "2m3wnn7qIqyh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#anlysis of data by vizualisation\n",
        "fig,ax=plt.subplots(figsize=(20,8))\n",
        "sns.pointplot(data=data,x='Hour',y='Rented Bike Count',hue='Weekend',ax=ax)\n",
        "ax.set(title='Count of Rented bikes acording to weekend ')"
      ],
      "metadata": {
        "id": "G6leYo9hJEPr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   In the week days which represent in blue colur show that the demand of the bike higher because of the office.\n",
        "*   Peak Time are 7 am to 9 am and 5 pm to 7 pm\n",
        "\n",
        "*   The orange colur represent the weekend days, and it show that the demand of rented bikes are very low specially in the morning hour but when the evening start from 4 pm to 8 pm the demand slightly increases\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "z_LZO2auJaot"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Numerical Feature Analysis"
      ],
      "metadata": {
        "id": "r-jYf2-u-UZH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#plotting histogram\n",
        "\n",
        "for col in numerical_features[:]:\n",
        "  sns.histplot(data[col])\n",
        "  plt.axvline(data[col].mean(), color='magenta', linestyle='dashed', linewidth=2)\n",
        "  plt.axvline(data[col].median(), color='cyan', linestyle='dashed', linewidth=2)\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "YTyLlTfA-fX_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ploting Regression plot of each columns of dataset v/s rented bike count columns\n",
        "\n",
        "for col in numerical_features[:]:\n",
        "  if col == 'Rented Bike Count':\n",
        "    pass\n",
        "  else:\n",
        "    sns.regplot(x=data[col],y=data[\"Rented Bike Count\"],line_kws={\"color\": \"red\"})\n",
        "\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "0aEMaEJR_fqf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   From the above regression plot of all numerical features we see that the columns 'Temperature', 'Wind_speed','Visibility', 'Dew_point_temperature', 'Solar_Radiation' are positively relation to the target variable.\n",
        "*   which means the rented bike count increases with increase of these features.\n",
        "\n",
        "*   'Rainfall','Snowfall','Humidity' these features are negatively related with the target variaable which means the rented bike count decreases when these features increase.\n"
      ],
      "metadata": {
        "id": "HKUMeSNFAC6d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Relationship between numerical variable and 'Rented Bike Count'"
      ],
      "metadata": {
        "id": "uIQLDfTsA0i6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#print the plot to analyze the relationship between rented bike count and numrical columns\n",
        "\n",
        "for col in numerical_features[:]:\n",
        "  if col == 'Rented Bike Count':\n",
        "    pass\n",
        "  else:\n",
        "    data.groupby(col).mean()['Rented Bike Count'].plot()\n",
        "\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "b2rqIx7LBBYq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   For Temprature- people like to ride bikes when it is pretty hot around 25°C in average\n",
        "*   For Humidity- People like to ride when humidity is low like in range of 10 - 15(%)\n",
        "\n",
        "*   For Wind Speend- demand of rented bike is uniformly distribute despite of wind speed but when the speed of wind was 7 m/s then the demand of bike also increase that clearly means peoples love to ride bikes when its little windy.\n",
        "*   For Visibility- People like to ride when visibility is more 500\n",
        "\n",
        "*   For Dew point temperature- \"Dew_point_temperature' is almost same as the 'temperature' there is some similarity present\n",
        "*   For Solar Radiation- the amount of rented bikes is huge, when there is solar radiation, the counter of rents is around 1000\n",
        "\n",
        "*   For Rainfall- rains a lot the demand of of rent bikes is not decreasing, here for example even if we have 20 mm of rain there is a big peak of rented bikes\n",
        "*   For Snowfall- the amount of rented bike is very low When we have more than 4 cm of snow, the bike rents is much lower\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-KIqS4AhDnrn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "#### Correlation Heatmap"
      ],
      "metadata": {
        "id": "NC_X3p0fY2L0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation Heatmap visualization code of datasets\n",
        "plt.figure(figsize=(25,20))\n",
        "sns.heatmap(data.corr(),annot=True,cmap=\"coolwarm\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xyC9zolEZNRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Multicollinearity\n",
        "\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "def calc_vif(X):\n",
        "\n",
        "   # Calculating VIF\n",
        "   vif = pd.DataFrame()\n",
        "   vif[\"variables\"] = X.columns\n",
        "   vif[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
        "\n",
        "   return(vif)"
      ],
      "metadata": {
        "id": "eOu618RzNrbN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calc_vif(df[[i for i in df.describe().columns if i not in ['Rented Bike Count','Dew point temperature(°C)'] ]])"
      ],
      "metadata": {
        "id": "54cK2xiiNxtU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "#### Pair Plot"
      ],
      "metadata": {
        "id": "q29F0dvdveiT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pair Plot visualization code\n",
        "sns.pairplot(data, hue ='Rented Bike Count')"
      ],
      "metadata": {
        "id": "o58-TEIhveiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### one hot encoding"
      ],
      "metadata": {
        "id": "85aiEz2wzJ-7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#creating Dummy variable for categorical columns\n",
        "dummy_categorical_feature= pd.get_dummies(categorical_features,drop_first=True)"
      ],
      "metadata": {
        "id": "DUB5_fnq1kUF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dummy_categorical_feature.head()"
      ],
      "metadata": {
        "id": "6Qu44xBC2MQ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#concating numeric columns and dummy columns and creating final df\n",
        "final_df= pd.concat([dummy_categorical_feature,numerical_features],axis=1)"
      ],
      "metadata": {
        "id": "TzXph_JL14Ci"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_df.head()"
      ],
      "metadata": {
        "id": "VSSc5Wa02FnA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Train Test split for regression"
      ],
      "metadata": {
        "id": "Njex3ua_y5L9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X=final_df.drop(['Rented Bike Count'],axis=1)\n",
        "y=np.sqrt(final_df['Rented Bike Count'])"
      ],
      "metadata": {
        "id": "MUn_pDgVyO8A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling the data\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)"
      ],
      "metadata": {
        "id": "Pe0GALN_37FU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creat test and train data\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.20, random_state=0)\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ],
      "metadata": {
        "id": "eMdngfDbyleS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Linear Regression"
      ],
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use a Linear regression model to fit the algorithm and perdict the model\n",
        "from sklearn.linear_model import LinearRegression\n",
        "lr = LinearRegression()\n",
        "reg= LinearRegression().fit(X_train, y_train)\n",
        "\n",
        "#get the X_train and X-test value\n",
        "y_pred_train=reg.predict(X_train)\n",
        "y_pred_test=reg.predict(X_test)\n",
        "\n",
        "#check the score\n",
        "print(reg.score(X_train, y_train))\n",
        "\n",
        "print('---------------------------------------------------------------------------------------------------------------------')\n",
        "\n",
        "#check the coefficeint\n",
        "print(reg.coef_)"
      ],
      "metadata": {
        "id": "7ebyywQieS1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Train Data Score Chart for Linear Regression"
      ],
      "metadata": {
        "id": "YcK5rsD9MPQC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import the module\n",
        "from sklearn.metrics import mean_squared_error\n",
        "#calculate MSE\n",
        "MSE_lr_train= mean_squared_error((y_train), (y_pred_train))\n",
        "print(\"MSE :\",MSE_lr_train)\n",
        "\n",
        "#calculate RMSE\n",
        "RMSE_lr_train=np.sqrt(MSE_lr_train)\n",
        "print(\"RMSE :\",RMSE_lr_train)\n",
        "\n",
        "# import the module\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "#calculate MAE\n",
        "MAE_lr_train= mean_absolute_error(y_train, y_pred_train)\n",
        "print(\"MAE :\",MAE_lr_train)\n",
        "\n",
        "\n",
        "\n",
        "#import the module\n",
        "from sklearn.metrics import r2_score\n",
        "#calculate r2 and adjusted r2\n",
        "r2_lr_train= r2_score(y_train, y_pred_train)\n",
        "print(\"R2 :\",r2_lr_train)\n",
        "Adjusted_R2_lr_train = (1-(1-r2_score(y_train, y_pred_train))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)) )\n",
        "print(\"Adjusted R2 :\",1-(1-r2_score(y_train, y_pred_train))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)) )"
      ],
      "metadata": {
        "id": "aYGNVLyGzvWa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Test Data Score Chart for Linear Regression"
      ],
      "metadata": {
        "id": "n88_DRzeMfQ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import the module\n",
        "from sklearn.metrics import mean_squared_error\n",
        "#calculate MSE\n",
        "MSE_lr_test= mean_squared_error((y_test), (y_pred_test))\n",
        "print(\"MSE :\",MSE_lr_test)\n",
        "\n",
        "#calculate RMSE\n",
        "RMSE_lr_test=np.sqrt(MSE_lr_test)\n",
        "print(\"RMSE :\",RMSE_lr_test)\n",
        "\n",
        "# import the module\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "#calculate MAE\n",
        "MAE_lr_test= mean_absolute_error((y_test), (y_pred_test))\n",
        "print(\"MAE :\",MAE_lr_test)\n",
        "\n",
        "\n",
        "\n",
        "#import the module\n",
        "from sklearn.metrics import r2_score\n",
        "#calculate r2 and adjusted r2\n",
        "r2_lr_test= r2_score((y_test), (y_pred_test))\n",
        "print(\"R2 :\",r2_lr_test)\n",
        "Adjusted_R2_lr_test = (1-(1-r2_score((y_test), (y_pred_test)))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)) )\n",
        "print(\"Adjusted R2 :\",1-(1-r2_score((y_test), (y_pred_test)))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)) )"
      ],
      "metadata": {
        "id": "9JhreTVJ4gO7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "ArJBuiUVfxKd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "### Heteroscadacity\n",
        "plt.scatter((y_pred_test),(y_test)-(y_pred_test))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rqD5ZohzfxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plot the figure\n",
        "plt.figure(figsize=(15,10))\n",
        "plt.plot(y_pred_test)\n",
        "plt.plot(np.array(y_test))\n",
        "plt.legend([\"Predicted\",\"Actual\"])\n",
        "plt.xlabel('No of Test Data')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Wu9phI71M534"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LASSO REGRESSION"
      ],
      "metadata": {
        "id": "dJ2tPlVmpsJ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an instance of Lasso Regression implementation\n",
        "from sklearn.linear_model import Lasso\n",
        "lasso = Lasso(alpha=1.0, max_iter=3000)\n",
        "# Fit the Lasso model\n",
        "lasso.fit(X_train, y_train)\n",
        "\n",
        "#get the X_train and X-test value\n",
        "y_pred_train_lasso=lasso.predict(X_train)\n",
        "y_pred_test_lasso=lasso.predict(X_test)\n",
        "\n",
        "# Create the model score\n",
        "print(lasso.score(X_test, y_test), lasso.score(X_train, y_train))\n",
        "\n",
        "print('-----------------------------------------------------------------')\n",
        "\n",
        "#check the coefficeint\n",
        "print(lasso.coef_)"
      ],
      "metadata": {
        "id": "9aI-7mQEAjz3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For Train Data"
      ],
      "metadata": {
        "id": "0ibfVdVsXmvl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "#calculate MSE\n",
        "MSE_l_train= mean_squared_error((y_train), (y_pred_train_lasso))\n",
        "print(\"MSE :\",MSE_l_train)\n",
        "\n",
        "#calculate RMSE\n",
        "RMSE_l_train=np.sqrt(MSE_l_train)\n",
        "print(\"RMSE :\",RMSE_l_train)\n",
        "\n",
        "\n",
        "#calculate MAE\n",
        "MAE_l_train= mean_absolute_error(y_train, y_pred_train_lasso)\n",
        "print(\"MAE :\",MAE_l_train)\n",
        "\n",
        "\n",
        "from sklearn.metrics import r2_score\n",
        "#calculate r2 and adjusted r2\n",
        "r2_l_train= r2_score(y_train, y_pred_train_lasso)\n",
        "print(\"R2 :\",r2_l_train)\n",
        "Adjusted_R2_l_train = (1-(1-r2_score(y_train, y_pred_train_lasso))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)) )\n",
        "print(\"Adjusted R2 :\",1-(1-r2_score(y_train, y_pred_train_lasso))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)) )"
      ],
      "metadata": {
        "id": "GhXnZrOQBUmf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For Test Data"
      ],
      "metadata": {
        "id": "R6FuwQdYX5cx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "#calculate MSE\n",
        "MSE_l_test= mean_squared_error(y_test, y_pred_test_lasso)\n",
        "print(\"MSE :\",MSE_l_test)\n",
        "\n",
        "#calculate RMSE\n",
        "RMSE_l_test=np.sqrt(MSE_l_test)\n",
        "print(\"RMSE :\",RMSE_l_test)\n",
        "\n",
        "\n",
        "#calculate MAE\n",
        "MAE_l_test= mean_absolute_error(y_test, y_pred_test_lasso)\n",
        "print(\"MAE :\",MAE_l_test)\n",
        "\n",
        "\n",
        "from sklearn.metrics import r2_score\n",
        "#calculate r2 and adjusted r2\n",
        "r2_l_test= r2_score((y_test), (y_pred_test_lasso))\n",
        "print(\"R2 :\",r2_l_test)\n",
        "Adjusted_R2_l_test=(1-(1-r2_score((y_test), (y_pred_test_lasso)))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)) )\n",
        "print(\"Adjusted R2 :\",1-(1-r2_score((y_test), (y_pred_test_lasso)))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)) )"
      ],
      "metadata": {
        "id": "_UJp2LqBBfU8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "JWYfwnehpsJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "#Plot the figure\n",
        "plt.figure(figsize=(15,10))\n",
        "plt.plot(np.array(y_pred_test_lasso))\n",
        "plt.plot(np.array((y_test)))\n",
        "plt.legend([\"Predicted\",\"Actual\"])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "06fPPTLLAiPx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Heteroscadacity\n",
        "plt.scatter((y_pred_test_lasso),(y_test-y_pred_test_lasso))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "yEl-hgQWpsJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "-jK_YjpMpsJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use a GridSearch CV for hyperparameter tuning of laaso regression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "params = {'alpha': [0.0001, 0.001, 0.01, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0,\n",
        "                    10.0, 20, 50, 100, 500, 1000 ]}\n",
        "\n",
        "grid_cv_lasso = GridSearchCV(estimator=lasso,\n",
        "                       param_grid=params,\n",
        "                       scoring='neg_mean_absolute_error',\n",
        "                       cv=5,\n",
        "                       return_train_score=True,\n",
        "                       verbose=1)\n",
        "grid_lasso_reg= grid_cv_lasso.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "Dn0EOfS6psJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#get the X_train and X-test value\n",
        "y_pred_train_lasso_grid=grid_lasso_reg.predict(X_train)\n",
        "y_pred_test_lasso_grid=grid_lasso_reg.predict(X_test)\n",
        "\n",
        "# Create the model score\n",
        "print(grid_lasso_reg.score(X_test, y_test), grid_lasso_reg.score(X_train, y_train))\n",
        "\n"
      ],
      "metadata": {
        "id": "aZwMBuwoDKcw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For Train Data"
      ],
      "metadata": {
        "id": "-P7u_7l_YygG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "#calculate MSE\n",
        "MSE_l_train_grid= mean_squared_error((y_train), (y_pred_train_lasso_grid))\n",
        "print(\"MSE :\",MSE_l_train_grid)\n",
        "\n",
        "#calculate RMSE\n",
        "RMSE_l_train_grid=np.sqrt(MSE_l_train_grid)\n",
        "print(\"RMSE :\",RMSE_l_train_grid)\n",
        "\n",
        "\n",
        "#calculate MAE\n",
        "MAE_l_train_grid= mean_absolute_error(y_train, y_pred_train_lasso_grid)\n",
        "print(\"MAE :\",MAE_l_train_grid)\n",
        "\n",
        "\n",
        "from sklearn.metrics import r2_score\n",
        "#calculate r2 and adjusted r2\n",
        "r2_l_train_grid= r2_score(y_train, y_pred_train_lasso_grid)\n",
        "print(\"R2 :\",r2_l_train_grid)\n",
        "Adjusted_R2_l_train_grid = (1-(1-r2_score(y_train, y_pred_train_lasso_grid))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)) )\n",
        "print(\"Adjusted R2 :\",1-(1-r2_score(y_train, y_pred_train_lasso_grid))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)) )"
      ],
      "metadata": {
        "id": "ZefA6AjXDblt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For Test Data"
      ],
      "metadata": {
        "id": "I9aJoFljY0-3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "#calculate MSE\n",
        "MSE_l_test_grid= mean_squared_error(y_test, y_pred_test_lasso_grid)\n",
        "print(\"MSE :\",MSE_l_test_grid)\n",
        "\n",
        "#calculate RMSE\n",
        "RMSE_l_test_grid=np.sqrt(MSE_l_test_grid)\n",
        "print(\"RMSE :\",RMSE_l_test_grid)\n",
        "\n",
        "\n",
        "#calculate MAE\n",
        "MAE_l_test_grid= mean_absolute_error(y_test, y_pred_test_lasso_grid)\n",
        "print(\"MAE :\",MAE_l_test_grid)\n",
        "\n",
        "\n",
        "from sklearn.metrics import r2_score\n",
        "#calculate r2 and adjusted r2\n",
        "r2_l_test_grid= r2_score((y_test), (y_pred_test_lasso_grid))\n",
        "print(\"R2 :\",r2_l_test_grid)\n",
        "Adjusted_R2_l_test_grid=(1-(1-r2_score((y_test), (y_pred_test_lasso_grid)))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)) )\n",
        "print(\"Adjusted R2 :\",1-(1-r2_score((y_test), (y_pred_test_lasso_grid)))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)) )"
      ],
      "metadata": {
        "id": "HGYwiOmYBL1C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### RIDGE REGRESSION"
      ],
      "metadata": {
        "id": "Fze-IPXLpx6K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import the packages\n",
        "from sklearn.linear_model import Ridge\n",
        "\n",
        "ridge= Ridge(alpha=0.1)\n",
        "\n",
        "# Fit the Lasso model\n",
        "ridge.fit(X_train, y_train)\n",
        "\n",
        "#get the X_train and X-test value\n",
        "y_pred_train_ridge=ridge.predict(X_train)\n",
        "y_pred_test_ridge=ridge.predict(X_test)\n",
        "\n",
        "# Create the model score\n",
        "print(ridge.score(X_test, y_test), ridge.score(X_train, y_train))\n",
        "\n",
        "print('-----------------------------------------------------------------')\n",
        "\n",
        "#check the coefficeint\n",
        "print(ridge.coef_)"
      ],
      "metadata": {
        "id": "FFrSXAtrpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For Train Data"
      ],
      "metadata": {
        "id": "ZDXixdG3ZN6A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import the packages\n",
        "from sklearn.metrics import mean_squared_error\n",
        "#calculate MSE\n",
        "MSE_r_train= mean_squared_error((y_train), (y_pred_train_ridge))\n",
        "print(\"MSE :\",MSE_r_train)\n",
        "\n",
        "#calculate RMSE\n",
        "RMSE_r_train=np.sqrt(MSE_r_train)\n",
        "print(\"RMSE :\",RMSE_r_train)\n",
        "\n",
        "\n",
        "#calculate MAE\n",
        "MAE_r_train= mean_absolute_error(y_train, y_pred_train_ridge)\n",
        "print(\"MAE :\",MAE_r_train)\n",
        "\n",
        "\n",
        "#import the packages\n",
        "from sklearn.metrics import r2_score\n",
        "#calculate r2 and adjusted r2\n",
        "r2_r_train= r2_score(y_train, y_pred_train_ridge)\n",
        "print(\"R2 :\",r2_r_train)\n",
        "Adjusted_R2_r_train=(1-(1-r2_score(y_train, y_pred_train_ridge))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)) )\n",
        "print(\"Adjusted R2 :\",1-(1-r2_score(y_train, y_pred_train_ridge))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)) )"
      ],
      "metadata": {
        "id": "XPmAyx34GeTQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For Test Data"
      ],
      "metadata": {
        "id": "9A-dtVSnZpJr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import the packages\n",
        "from sklearn.metrics import mean_squared_error\n",
        "#calculate MSE\n",
        "MSE_r_test= mean_squared_error(y_test, y_pred_test_ridge)\n",
        "print(\"MSE :\",MSE_r_test)\n",
        "\n",
        "#calculate RMSE\n",
        "RMSE_r_test=np.sqrt(MSE_r_test)\n",
        "print(\"RMSE :\",RMSE_r_test)\n",
        "\n",
        "\n",
        "#calculate MAE\n",
        "MAE_r_test= mean_absolute_error(y_test, y_pred_test_ridge)\n",
        "print(\"MAE :\",MAE_r_test)\n",
        "\n",
        "\n",
        "#import the packages\n",
        "from sklearn.metrics import r2_score\n",
        "#calculate r2 and adjusted r2\n",
        "r2_r_test= r2_score((y_test), (y_pred_test_ridge))\n",
        "print(\"R2 :\",r2_r_test)\n",
        "Adjusted_R2_r_test=(1-(1-r2_score((y_test), (y_pred_test_ridge)))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)) )\n",
        "print(\"Adjusted R2 :\",1-(1-r2_score((y_test), (y_pred_test_ridge)))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)) )"
      ],
      "metadata": {
        "id": "yT9umMZUI5Uh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "7AN1z2sKpx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "#Plot the figure\n",
        "plt.figure(figsize=(15,10))\n",
        "plt.plot((y_pred_test_ridge))\n",
        "plt.plot((np.array(y_test)))\n",
        "plt.legend([\"Predicted\",\"Actual\"])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xIY4lxxGpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Heteroscadacity\n",
        "plt.scatter((y_pred_test_ridge),(y_test)-(y_pred_test_ridge))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "19kuBQhiN3bS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "9PIHJqyupx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use a GridSearch CV for hyperparameter tuning of ridge regression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "params = {'alpha': [0.0001, 0.001, 0.01, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0,\n",
        "                    10.0, 20, 50, 100, 500, 1000 ]}\n",
        "\n",
        "grid_cv_ridge = GridSearchCV(estimator=ridge,\n",
        "                       param_grid=params,\n",
        "                       scoring='neg_mean_absolute_error',\n",
        "                       cv=5,\n",
        "                       return_train_score=True,\n",
        "                       verbose=1)\n",
        "grid_ridge_reg= grid_cv_lasso.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "eSVXuaSKpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#get the X_train and X-test value\n",
        "y_pred_train_ridge_grid=grid_ridge_reg.predict(X_train)\n",
        "y_pred_test_ridge_grid=grid_ridge_reg.predict(X_test)\n",
        "\n",
        "# Create the model score\n",
        "print(grid_ridge_reg.score(X_test, y_test), grid_ridge_reg.score(X_train, y_train))"
      ],
      "metadata": {
        "id": "-yDNMtOvIL_V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For Train Data"
      ],
      "metadata": {
        "id": "WN5NDvvQaBUF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import the packages\n",
        "from sklearn.metrics import mean_squared_error\n",
        "#calculate MSE\n",
        "MSE_r_train_grid= mean_squared_error((y_train), (y_pred_train_ridge_grid))\n",
        "print(\"MSE :\",MSE_r_train_grid)\n",
        "\n",
        "#calculate RMSE\n",
        "RMSE_r_train_grid=np.sqrt(MSE_r_train_grid)\n",
        "print(\"RMSE :\",RMSE_r_train_grid)\n",
        "\n",
        "\n",
        "#calculate MAE\n",
        "MAE_r_train_grid= mean_absolute_error(y_train, y_pred_train_ridge_grid)\n",
        "print(\"MAE :\",MAE_r_train_grid)\n",
        "\n",
        "\n",
        "#import the packages\n",
        "from sklearn.metrics import r2_score\n",
        "#calculate r2 and adjusted r2\n",
        "r2_r_train_grid= r2_score(y_train, y_pred_train_ridge_grid)\n",
        "print(\"R2 :\",r2_r_train_grid)\n",
        "Adjusted_R2_r_train_grid=(1-(1-r2_score(y_train, y_pred_train_ridge_grid))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)) )\n",
        "print(\"Adjusted R2 :\",1-(1-r2_score(y_train, y_pred_train_ridge_grid))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)) )"
      ],
      "metadata": {
        "id": "Tty1WeU_JF_q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For Test Data"
      ],
      "metadata": {
        "id": "xm-o3OmraYGA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import the packages\n",
        "from sklearn.metrics import mean_squared_error\n",
        "#calculate MSE\n",
        "MSE_r_test_grid= mean_squared_error(y_test, y_pred_test_ridge_grid)\n",
        "print(\"MSE :\",MSE_r_test_grid)\n",
        "\n",
        "#calculate RMSE\n",
        "RMSE_r_test_grid=np.sqrt(MSE_r_test_grid)\n",
        "print(\"RMSE :\",RMSE_r_test_grid)\n",
        "\n",
        "\n",
        "#calculate MAE\n",
        "MAE_r_test_grid= mean_absolute_error(y_test, y_pred_test_ridge_grid)\n",
        "print(\"MAE :\",MAE_r_test_grid)\n",
        "\n",
        "\n",
        "#import the packages\n",
        "from sklearn.metrics import r2_score\n",
        "#calculate r2 and adjusted r2\n",
        "r2_r_test_grid= r2_score((y_test), (y_pred_test_ridge_grid))\n",
        "print(\"R2 :\",r2_r_test_grid)\n",
        "Adjusted_R2_r_test_grid=(1-(1-r2_score((y_test), (y_pred_test_ridge_grid)))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)) )\n",
        "print(\"Adjusted R2 :\",1-(1-r2_score((y_test), (y_pred_test_ridge_grid)))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)) )"
      ],
      "metadata": {
        "id": "-1HAyZkPJX85"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ELASTIC NET REGRESSION"
      ],
      "metadata": {
        "id": "5hN0UbkzJxB_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import the packages\n",
        "#a * L1 + b * L2\n",
        "#alpha = a + b and l1_ratio = a / (a + b)\n",
        "from sklearn.linear_model import ElasticNet\n",
        "elasticnet = ElasticNet(alpha=0.1, l1_ratio=0.5)\n",
        "\n",
        "#FIT THE MODEL\n",
        "elasticnet.fit(X_train,y_train)\n",
        "\n",
        "#get the X_train and X-test value\n",
        "y_pred_train_en=elasticnet.predict(X_train)\n",
        "y_pred_test_en=elasticnet.predict(X_test)\n",
        "\n",
        "#check the score\n",
        "elasticnet.score(X_train, y_train)"
      ],
      "metadata": {
        "id": "EY5gj5kBJrsK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For Train Data"
      ],
      "metadata": {
        "id": "U4joH2UNa0ZT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import the packages\n",
        "from sklearn.metrics import mean_squared_error\n",
        "#calculate MSE\n",
        "MSE_e_train= mean_squared_error((y_train), (y_pred_train_en))\n",
        "print(\"MSE :\",MSE_e_train)\n",
        "\n",
        "#calculate RMSE\n",
        "RMSE_e_train=np.sqrt(MSE_e_train)\n",
        "print(\"RMSE :\",RMSE_e_train)\n",
        "\n",
        "\n",
        "#calculate MAE\n",
        "MAE_e_train= mean_absolute_error(y_train, y_pred_train_en)\n",
        "print(\"MAE :\",MAE_e_train)\n",
        "\n",
        "\n",
        "#import the packages\n",
        "from sklearn.metrics import r2_score\n",
        "#calculate r2 and adjusted r2\n",
        "r2_e_train= r2_score(y_train, y_pred_train_en)\n",
        "print(\"R2 :\",r2_e_train)\n",
        "Adjusted_R2_e_train=(1-(1-r2_score(y_train, y_pred_train_en))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)) )\n",
        "print(\"Adjusted R2 :\",1-(1-r2_score(y_train, y_pred_train_en))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)) )"
      ],
      "metadata": {
        "id": "pQ-q-FtLKPYY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For Test Data"
      ],
      "metadata": {
        "id": "ieg0GCR_bEc1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import the packages\n",
        "from sklearn.metrics import mean_squared_error\n",
        "#calculate MSE\n",
        "MSE_e_test= mean_squared_error(y_test, y_pred_test_en)\n",
        "print(\"MSE :\",MSE_e_test)\n",
        "\n",
        "#calculate RMSE\n",
        "RMSE_e_test=np.sqrt(MSE_e_test)\n",
        "print(\"RMSE :\",RMSE_e_test)\n",
        "\n",
        "\n",
        "#calculate MAE\n",
        "MAE_e_test= mean_absolute_error(y_test, y_pred_test_en)\n",
        "print(\"MAE :\",MAE_e_test)\n",
        "\n",
        "\n",
        "#import the packages\n",
        "from sklearn.metrics import r2_score\n",
        "#calculate r2 and adjusted r2\n",
        "r2_e_test= r2_score((y_test), (y_pred_test_en))\n",
        "print(\"R2 :\",r2_e_test)\n",
        "Adjusted_R2_e_test=(1-(1-r2_score((y_test), (y_pred_test_en)))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)) )\n",
        "print(\"Adjusted R2 :\",1-(1-r2_score((y_test), (y_pred_test_en)))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)) )"
      ],
      "metadata": {
        "id": "IrKGrBEDKW5o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plot the figure\n",
        "plt.figure(figsize=(15,10))\n",
        "plt.plot(np.array(y_pred_test_en))\n",
        "plt.plot((np.array(y_test)))\n",
        "plt.legend([\"Predicted\",\"Actual\"])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HkGBt3NbOIm-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Heteroscadacity\n",
        "plt.scatter((y_pred_test_en),(y_test)-(y_pred_test_en))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "F-RhSsKYONlb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "mHy4VWLCKhHh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use a GridSearch CV for hyperparameter tuning of ridge regression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "params = {'alpha': [0.0001, 0.001, 0.01, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0,\n",
        "                    10.0, 20, 50, 100, 500, 1000 ]}\n",
        "\n",
        "grid_cv_en = GridSearchCV(estimator=elasticnet,\n",
        "                       param_grid=params,\n",
        "                       scoring='neg_mean_absolute_error',\n",
        "                       cv=5,\n",
        "                       return_train_score=True,\n",
        "                       verbose=1)\n",
        "grid_en_reg= grid_cv_en.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "ZW40sGwwKi_4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#get the X_train and X-test value\n",
        "y_pred_train_en_grid=grid_en_reg.predict(X_train)\n",
        "y_pred_test_en_grid=grid_en_reg.predict(X_test)\n",
        "\n",
        "# Create the model score\n",
        "print(grid_en_reg.score(X_test, y_test), grid_en_reg.score(X_train, y_train))"
      ],
      "metadata": {
        "id": "CofcAA70LFRo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For Train Data"
      ],
      "metadata": {
        "id": "8fQLmF_RbSih"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import the packages\n",
        "from sklearn.metrics import mean_squared_error\n",
        "#calculate MSE\n",
        "MSE_e_train_grid= mean_squared_error((y_train), (y_pred_train_en_grid))\n",
        "print(\"MSE :\",MSE_e_train_grid)\n",
        "\n",
        "#calculate RMSE\n",
        "RMSE_e_train_grid=np.sqrt(MSE_e_train_grid)\n",
        "print(\"RMSE :\",RMSE_e_train_grid)\n",
        "\n",
        "\n",
        "#calculate MAE\n",
        "MAE_e_train_grid= mean_absolute_error(y_train, y_pred_train_en_grid)\n",
        "print(\"MAE :\",MAE_e_train_grid)\n",
        "\n",
        "\n",
        "#import the packages\n",
        "from sklearn.metrics import r2_score\n",
        "#calculate r2 and adjusted r2\n",
        "r2_e_train_grid= r2_score(y_train, y_pred_train_en_grid)\n",
        "print(\"R2 :\",r2_e_train_grid)\n",
        "Adjusted_R2_e_train_grid=(1-(1-r2_score(y_train, y_pred_train_en_grid))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)) )\n",
        "print(\"Adjusted R2 :\",1-(1-r2_score(y_train, y_pred_train_en_grid))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)) )"
      ],
      "metadata": {
        "id": "kOuDUouwLVri"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For Test Data"
      ],
      "metadata": {
        "id": "CTKgzDgCbqIZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import the packages\n",
        "from sklearn.metrics import mean_squared_error\n",
        "#calculate MSE\n",
        "MSE_e_test_grid= mean_squared_error(y_test, y_pred_test_en_grid)\n",
        "print(\"MSE :\",MSE_e_test_grid)\n",
        "\n",
        "#calculate RMSE\n",
        "RMSE_e_test_grid=np.sqrt(MSE_e_test_grid)\n",
        "print(\"RMSE :\",RMSE_e_test_grid)\n",
        "\n",
        "\n",
        "#calculate MAE\n",
        "MAE_e_test_grid= mean_absolute_error(y_test, y_pred_test_en_grid)\n",
        "print(\"MAE :\",MAE_e_test_grid)\n",
        "\n",
        "\n",
        "#import the packages\n",
        "from sklearn.metrics import r2_score\n",
        "#calculate r2 and adjusted r2\n",
        "r2_e_test_grid= r2_score((y_test), (y_pred_test_en_grid))\n",
        "print(\"R2 :\",r2_e_test_grid)\n",
        "Adjusted_R2_e_test_grid=(1-(1-r2_score((y_test), (y_pred_test_en_grid)))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)) )\n",
        "print(\"Adjusted R2 :\",1-(1-r2_score((y_test), (y_pred_test_en_grid)))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)) )"
      ],
      "metadata": {
        "id": "oKzyM2PZLjqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluating the models"
      ],
      "metadata": {
        "id": "g3rez1P-f2CU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1- Without Hyperameter Tuning"
      ],
      "metadata": {
        "id": "pEhwBvwPf8ga"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For Train Datasets Evalution Dataframe"
      ],
      "metadata": {
        "id": "X-TlLFFIgChe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "regression = ['LinearRegression', 'LASSO REGRESSION', 'RIDGE REGRESSION', 'ELASTIC NET REGRESSION']\n",
        "\n",
        "MSE = [MSE_lr_train, MSE_l_train, MSE_r_train, MSE_e_train]\n",
        "RMSE = [RMSE_lr_train, RMSE_l_train, RMSE_r_train, RMSE_e_train]\n",
        "MAE = [MAE_lr_train, MAE_l_train, MAE_r_train, MAE_e_train]\n",
        "R2 = [r2_lr_train, r2_l_train, r2_r_train, r2_e_train]\n",
        "Adjusted_R2 = [Adjusted_R2_lr_train, Adjusted_R2_l_train, Adjusted_R2_r_train, Adjusted_R2_e_train]"
      ],
      "metadata": {
        "id": "oZuMtHI8OUbo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame({'regression_train':regression, 'MSE': MSE, 'RMSE': RMSE, 'R2': R2,'Adjusted_R2':Adjusted_R2})"
      ],
      "metadata": {
        "id": "1PcJVEPJgefd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For Test Datasets Evalution Dataframe"
      ],
      "metadata": {
        "id": "66kfVjzYgNwa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "regression = ['LinearRegression', 'LASSO REGRESSION', 'RIDGE REGRESSION', 'ELASTIC NET REGRESSION']\n",
        "\n",
        "MSE = [MSE_lr_test, MSE_l_test, MSE_r_test, MSE_e_test]\n",
        "RMSE = [RMSE_lr_test, RMSE_l_test, RMSE_r_test, RMSE_e_test]\n",
        "MAE = [MAE_lr_test, MAE_l_test, MAE_r_test, MAE_e_test]\n",
        "R2 = [r2_lr_test, r2_l_test, r2_r_test, r2_e_test]\n",
        "Adjusted_R2 = [Adjusted_R2_lr_test, Adjusted_R2_l_test, Adjusted_R2_r_test, Adjusted_R2_e_test]"
      ],
      "metadata": {
        "id": "OP74ybVyeU7m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame({'regression_test':regression, 'MSE': MSE, 'RMSE': RMSE, 'R2': R2,'Adjusted_R2':Adjusted_R2})"
      ],
      "metadata": {
        "id": "YfQ3eBBZg5L6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2- After Hyperameter Tuning"
      ],
      "metadata": {
        "id": "0Yb3oK5VgRSr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For Train Datasets Evalution Dataframe"
      ],
      "metadata": {
        "id": "0cgF4orjgWXh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "regression = ['LASSO REGRESSION', 'RIDGE REGRESSION', 'ELASTIC NET REGRESSION']\n",
        "\n",
        "MSE = [MSE_l_train_grid, MSE_r_train_grid, MSE_e_train_grid]\n",
        "RMSE = [RMSE_l_train_grid, RMSE_r_train_grid, RMSE_e_train_grid]\n",
        "MAE = [MAE_l_train_grid, MAE_r_train_grid, MAE_e_train_grid]\n",
        "R2 = [r2_l_train_grid, r2_r_train_grid, r2_e_train_grid]\n",
        "Adjusted_R2 = [Adjusted_R2_l_train_grid, Adjusted_R2_r_train_grid, Adjusted_R2_e_train_grid]"
      ],
      "metadata": {
        "id": "gX4Ci0ODfgqi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame({'regression_train_grid':regression, 'MSE': MSE, 'RMSE': RMSE, 'R2': R2,'Adjusted_R2':Adjusted_R2})"
      ],
      "metadata": {
        "id": "ABNi00-tg8fk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For Test Datasets Evalution Dataframe"
      ],
      "metadata": {
        "id": "0ErNgbIwgaJM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "regression = ['LASSO REGRESSION', 'RIDGE REGRESSION', 'ELASTIC NET REGRESSION']\n",
        "\n",
        "MSE = [MSE_l_test_grid, MSE_r_test_grid, MSE_e_test_grid]\n",
        "RMSE = [RMSE_l_test_grid, RMSE_r_test_grid, RMSE_e_test_grid]\n",
        "MAE = [MAE_l_test_grid, MAE_r_test_grid, MAE_e_test_grid]\n",
        "R2 = [r2_l_test_grid, r2_r_test_grid, r2_e_test_grid]\n",
        "Adjusted_R2 = [Adjusted_R2_l_test_grid, Adjusted_R2_r_test_grid, Adjusted_R2_e_test_grid]"
      ],
      "metadata": {
        "id": "dEHERnMxfAQO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame({'regression_test_grid':regression, 'MSE': MSE, 'RMSE': RMSE, 'R2': R2,'Adjusted_R2':Adjusted_R2})"
      ],
      "metadata": {
        "id": "QMahJoXCg_Fi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Congrats! Your model is successfully created and ready for deployment on a live server for a real user interaction !!!***"
      ],
      "metadata": {
        "id": "-Kee-DAl2viO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   No overfitting is seen.\n",
        "*   LinearRegression and RIDGE REGRESSION gives the highest R2 score of 75.9% recpectively for Train Set and 76% for Test set.\n",
        "\n"
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As this data is time dependent, the values for variables like temperature, windspeed, solar radiation etc., will not always be consistent. Therefore, there will be scenarios where the model might not perform well. As Machine learning is an exponentially evolving field, we will have to be prepared for all contingencies and also keep checking our model from time to time"
      ],
      "metadata": {
        "id": "e5fTixT4oKbT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    }
  ]
}